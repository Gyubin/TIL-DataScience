{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "## 1. 개념\n",
    "\n",
    "- 데이터가 많지 않으면 학습이 안좋게 될 수 있다. 특정 weight 값이 너무 커지거나 너무 작아질 수 있다. 이를 막기 위해 페널티를 준다.\n",
    "- 기존 Objective function(목표 함수)에 항을 하나 더한다.\n",
    "    + Ridge Regression: 모든 b의 값을 제곱해서 더한 값에 lambda를 곱해 적절히 조절해서 더해줌\n",
    "    + Lasso Regression: 모든 b의 절대값을 더해서 lambda를 곱해 더해줌\n",
    "\n",
    "\\begin{align}\n",
    "Ridge\\ regression = \\mathcal{l}(Y^{(i)},\\beta_0,\\beta_1,...,\\beta_p,X^{(i)}) + \\lambda\\|\\beta\\|^2 \\\\\n",
    "Lasso\\ regression = \\mathcal{l}(Y^{(i)},\\beta_0,\\beta_1,...,\\beta_p,X^{(i)}) + \\lambda\\|\\beta\\|_1\n",
    "\\end{align}\n",
    "    \n",
    "- 야구 선수들의 데이터를 활용하는데 18가지의 통계 수치(X)와 연봉(y)이다. 통계 수치들이 연봉에 어떻게 영향을 끼치는지 Multiple Linear Regression을 통해 알아본다.\n",
    "\n",
    "```\n",
    "Name,AtBat,Hits,HmRun,Runs,RBI,Walks,Years,CAtBat,CHits,CHmRun,CRuns,CRBI,CWalks,League,Division,PutOuts,Assists,Errors,Salary\n",
    "Mel Hall,442,131,18,68,77,33,6,1416,398,47,210,203,136,1,0,233,7,7,550\n",
    "Jerry Royster,257,66,5,31,26,32,14,3910,979,33,518,324,382,0,1,87,166,14,250\n",
    ".\n",
    ".\n",
    ".\n",
    "```\n",
    "\n",
    "## 2. 구현\n",
    "\n",
    "### 2.1 lambda 찾기\n",
    "\n",
    "가장 적합한 lambda를 찾는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_lambda_value_ridge_lasso(data):\n",
    "    \"\"\"\n",
    "    Implement Here\n",
    "    The grader will call this function to get the lambda value,\n",
    "    and run the functions with hidden test data.\n",
    "    Do not write exact value on best_lambda_ridge and best_lambda_lasso.\n",
    "    You should implement the function to find the best lambda value.\n",
    "    \"\"\"\n",
    "    response_var = -1\n",
    "    y_vec = data.ix[:, response_var].squeeze()\n",
    "    x_mat = data.ix[:, 1:-1].as_matrix()\n",
    "    x_mat = x_mat.reshape(-1, x_mat.shape[1])\n",
    "\n",
    "    from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "    ridgeregr = RidgeCV(cv=10, alphas=np.logspace(0, 100, 100))\n",
    "    ridgeregr.fit(x_mat, y_vec)\n",
    "    lassoregr = LassoCV(cv=10, n_alphas=100)\n",
    "    lassoregr.fit(x_mat, y_vec)\n",
    "    best_lambda_ridge = ridgeregr.alpha_\n",
    "    best_lambda_lasso = lassoregr.alpha_\n",
    "\n",
    "    return best_lambda_ridge, best_lambda_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Multiple LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_var_hitter(x_train, x_test, y_train, y_test):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    y_train = y_train.squeeze()\n",
    "    y_test = y_test.squeeze()\n",
    "\n",
    "    regr.fit(x_train, y_train)\n",
    "    predicted_y_test = regr.predict(x_test)\n",
    "    rss = np.sum((predicted_y_test - y_test) ** 2)\n",
    "    r2 = r2_score(y_test, predicted_y_test)\n",
    "    mse = mean_squared_error(y_test, predicted_y_test)\n",
    "    print(\"Coefficients: {}\".format(regr.coef_))\n",
    "    return rss, r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_var_hitter_ridge(x_train, x_test, y_train, y_test, best_lambda):\n",
    "    \"\"\"\n",
    "    Implement Here\n",
    "    \"\"\"\n",
    "    regr = linear_model.Ridge(best_lambda)\n",
    "    y_train = y_train.squeeze()\n",
    "    y_test = y_test.squeeze()\n",
    "\n",
    "    regr.fit(x_train, y_train)\n",
    "    predicted_y_test = regr.predict(x_test)\n",
    "    rss = np.sum((predicted_y_test - y_test) ** 2)\n",
    "    r2 = r2_score(y_test, predicted_y_test)\n",
    "    mse = mean_squared_error(y_test, predicted_y_test)\n",
    "    print(\"Coefficients: {}\".format(regr.coef_))\n",
    "    return rss, r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_var_hitter_lasso(x_train, x_test, y_train, y_test, best_lambda):\n",
    "    \"\"\"\n",
    "    Implement Here\n",
    "    \"\"\"\n",
    "    regr = linear_model.Lasso(best_lambda)\n",
    "\n",
    "    y_train = y_train.squeeze()\n",
    "    y_test = y_test.squeeze()\n",
    "    regr.fit(x_train, y_train)\n",
    "    predicted_y_test = regr.predict(x_test)\n",
    "\n",
    "    rss = np.sum((predicted_y_test - y_test) ** 2)\n",
    "    r2 = r2_score(y_test, predicted_y_test)\n",
    "    mse = mean_squared_error(y_test, predicted_y_test)\n",
    "    print(\"Coefficients: {}\".format(regr.coef_))\n",
    "    return rss, r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qbinson/.virtualenvs/python-ml/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  -2.15391889    8.55268886    7.29938765   -3.7183511    -1.24205258\n",
      "    6.89464226   -2.33107018   -0.16102897   -0.41444889   -1.90051069\n",
      "    2.36160191    1.47000757   -1.09836326  -30.75913147 -157.68650189\n",
      "    0.2030851     0.47563856   -5.22334094]\n",
      "Linear Regression Result\n",
      "RSS: 6064354.855091518\n",
      "R^2: 0.24157641420430032\n",
      "MSE: 96259.60087446854\n",
      "\n",
      "Coefficients: [  2.05757038e-01   8.35063924e-02   1.04531917e-02   4.75325137e-02\n",
      "   4.17217880e-02   3.94585343e-02  -2.18880318e-03   2.47718490e-02\n",
      "   1.27345479e-01   4.75903341e-02   1.22248755e-01   1.34699964e-01\n",
      "   2.44907813e-02   7.14419691e-05  -8.44355900e-04   2.03895708e-01\n",
      "   2.67533962e-02  -2.18812097e-04]\n",
      "Ridge Regression Result\n",
      "RSS: 4945796.651327149\n",
      "R^2: 0.3814661376936701\n",
      "MSE: 78504.70875122459\n",
      "Best lambda value: 11768119.524349991\n",
      "\n",
      "Coefficients: [-0.          1.72844984  0.          0.          0.          1.28206996\n",
      "  0.         -0.37538491  0.86815739 -0.          0.9752082   0.68444581\n",
      " -0.09191713 -0.         -0.          0.2010234   0.16668317 -0.        ]\n",
      "lasso Result\n",
      "RSS: 4938150.957830014\n",
      "R^2: 0.38242232749729343\n",
      "MSE: 78383.34853698434\n",
      "Best lambda value: 625.9997619417771\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qbinson/.virtualenvs/python-ml/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_data = pd.read_csv(\"./Hitters.csv\", header=0)\n",
    "    response_var = -1\n",
    "    y_train = training_data.ix[:, response_var].squeeze()\n",
    "\n",
    "    x_train = training_data.ix[:, 1:-1].as_matrix()\n",
    "    x_train = x_train.reshape(-1, x_train.shape[1])\n",
    "\n",
    "    test_data = pd.read_csv(\"./Hitters_Test.csv\", header=0)\n",
    "    y_test = test_data.ix[:, response_var].squeeze()\n",
    "\n",
    "    x_test = test_data.ix[:, 1:-1].as_matrix()\n",
    "    x_test = x_test.reshape(-1, x_test.shape[1])\n",
    "\n",
    "    # Linear Regression\n",
    "    rss, r2, mse = multi_var_hitter(x_train, x_test, y_train, y_test)\n",
    "    print(\"Linear Regression Result\")\n",
    "    print(\"RSS: {}\".format(rss))\n",
    "    print(\"R^2: {}\".format(r2))\n",
    "    print(\"MSE: {}\".format(mse))\n",
    "    print()\n",
    "\n",
    "    # Ridge Regression\n",
    "    best_lambda_ridge, best_lambda_lasso = get_best_lambda_value_ridge_lasso(training_data)\n",
    "    rss, r2, mse = multi_var_hitter_ridge(x_train, x_test, y_train, y_test, best_lambda_ridge)\n",
    "    print(\"Ridge Regression Result\")\n",
    "    print(\"RSS: {}\".format(rss))\n",
    "    print(\"R^2: {}\".format(r2))\n",
    "    print(\"MSE: {}\".format(mse))\n",
    "    print(\"Best lambda value: {}\".format(best_lambda_ridge))\n",
    "    print()\n",
    "\n",
    "    # lasso\n",
    "    rss, r2, mse = multi_var_hitter_lasso(x_train, x_test, y_train, y_test, best_lambda_lasso)\n",
    "    print(\"lasso Result\")\n",
    "    print(\"RSS: {}\".format(rss))\n",
    "    print(\"R^2: {}\".format(r2))\n",
    "    print(\"MSE: {}\".format(mse))\n",
    "    print(\"Best lambda value: {}\".format(best_lambda_lasso))\n",
    "    print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
