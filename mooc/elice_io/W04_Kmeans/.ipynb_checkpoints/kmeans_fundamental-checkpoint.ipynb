{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means\n",
    "\n",
    "## 1. Unsupervised learning\n",
    "\n",
    "- unlabeled data를 가지고 학습하는 방식이다. 즉 y값이 없기 때문에 지금까지 해왔던 y를 예측하는 것은 애초에 말이 안된다.\n",
    "- 목표: 데이터를 가장 잘 설명하는 어떤 구조, 형태를 학습하는 것\n",
    "- 주로 \"pattern\"을 찾는데 쓰인다. ex) coffee를 구매하는 고객은 차도 구매하는가?\n",
    "- 실세계에서 레이블이 있는 데이터를 갖기가 쉽지 않다. 그리고 이를 분류하는 것은 매우 어려우며 그래서 회사에선 주로 돈을 지불하면서 사람에게 labeling을 시킨다.\n",
    "\n",
    "## 2. Clustering\n",
    "\n",
    "- 몇 가지의 feature를 활용하여 비슷한 것들끼리 뭉치는 것\n",
    "- 정의\n",
    "    + 데이터를 구분하는 특정 영역을 의미\n",
    "    + 같은 cluster의 데이터는 서로 비슷(similarity가 높음)\n",
    "    + 다른 cluster의 데이터는 서로 다름(distance가 크다)\n",
    "- 거리 측정 방법: Euclidean distance(두 점 사이의 거리), Cosine distance(두 벡터 사이의 각도)\n",
    "- 종류\n",
    "    + Centroid-based clustering\n",
    "    + Distribution-based clustering\n",
    "    + Hierarchical clustering\n",
    "    + Density-based clustering\n",
    "\n",
    "## 3. K-means\n",
    "\n",
    "### 3.1 2가지 스텝\n",
    "\n",
    "- Assign: 데이터가 이미 분포돼있는 상황에서 랜덤으로 중심 2개를 assign 한다.\n",
    "- Optimize: 데이터들을 중심과의 거리가 더 짧은 쪽으로 분류한다.\n",
    "- 데이터의 군집이 새롭게 결정돼있으니 위의 Assign -> optimize 과정을 다시 실행한다.\n",
    "- 변화가 없을 때까지 반복\n",
    "\n",
    "### 3.2 정리\n",
    "\n",
    "- Input\n",
    "    + 클러스터 개수 K를 먼저 정한다.\n",
    "    + Data $X^{(1)},X^{(2)},...,X^{(N)}$\n",
    "- Algorithm\n",
    "    + 각 클러스터마다 중심을 랜덤하게 생성\n",
    "    + 변화가 없을 때까지 반복\n",
    "        * 모든 데이터에 대해서: 각 클러스터의 중심과 자신(해당 데이터)을 비교, 가장 가까운 클러스터를 기억\n",
    "        * 모든 클러스터에 대해서: 자신(해당 클러스터)에 할당된 데이터들의 중심 계산, 계산된 중심을 새로운 중심으로 설정 \n",
    "- Output\n",
    "    + 클러스터마다 가지는 데이터\n",
    "    + 클러스터의 중심\n",
    "- 조심해야할 것\n",
    "    + feature 간의 스케일이 다르면 문제가 발생할 수 있다. 로그를 씌우든 normalize를 하든, kernel을 쓰든 해서 스케일 조절해야한다.\n",
    "    + 첫 initial 포인트를 어디다 두는지에 따라서 결과가 달라진다. local minimum이 여럿 존재함. 그래서 랜덤으로 중심을 여러번 새로 설정해서 global minimum을 찾아야한다.\n",
    "\n",
    "### 3.3 Ensemble\n",
    "\n",
    "- 예를 들어 데이터가 uniform distribution인 경우 init point가 어딘지에 따라 분류가 매우 달라진다.\n",
    "- 그래서 랜덤으로 init한 것을 여럿 학습시킨 후 앙상블 다수결 방식으로 클러스터링한다.\n",
    "- sklearn의 kmeans에서 `n_init`이 몇 번 할건지 나타내는 파라미터다.\n",
    "    + k : 함수에서 디폴트는 8\n",
    "    + max_iter : 디폴트는 300. 최대 몇 번까지 assign과 optimization을 반복할 것이지\n",
    "    + n_init: 몇 번 이니셜라이즈를 새롭게 해서 앙상블을 할건지\n",
    "- 즉 앙상블을 하는 이유는 local minima에 빠지는 케이스를 최대한 무시하기 위해서다. 주로 k가 높아질 수록 local minima의 가능한 모양도 많아지고 가능성도 높아진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
