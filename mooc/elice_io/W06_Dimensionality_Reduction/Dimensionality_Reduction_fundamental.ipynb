{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "feature가 너무 많으면 계산 비용이 높아지고, 원치 않는 결과가 나올 수 있고, overfitting, 시각화 불가능 등의 나쁜 점이 많다. 적절하게 차원을 축소해서 데이터를 preprocessing하는 것이 필요하다.\n",
    "\n",
    "## 1. Feature selection\n",
    "\n",
    "- variable selection, attribute selection, variable subset selection 이라고도 불린다.\n",
    "- 주로 feature가 매우 많거나, feature에 비해 데이터 샘플이 적을 때 사용한다.\n",
    "- Feature selection을 하는 목적\n",
    "    + 모델을 단순화해서 설명하기 쉽도록 만들어준다.\n",
    "    + 훈련 시간 단축\n",
    "    + 차원의 저주 피하기\n",
    "    + 오버피팅을 방지해서 generalization 강화\n",
    "- 종류: Wrapper,filter, embedded(위키피디아 참조) \n",
    "\n",
    "## 2. Feature extraction\n",
    "\n",
    "숨겨진 새로운 feature를 찾아내기. 기존 feature를 조합해서 새로운 feature를 만든다는 의미다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
