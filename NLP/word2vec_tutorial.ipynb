{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os, sys\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare data\n",
    "\n",
    "### 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>meta</th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This paper advances the state of the art in te...</td>\n",
       "      <td>Hossein Hematialam, Wlodek Zadrozny</td>\n",
       "      <td>Tue, 13 Jun 2017 18:02:27 GMT (14kb) [v2] Wed,...</td>\n",
       "      <td>Computation and Language (cs.CL)</td>\n",
       "      <td>Identifying Condition-Action Statements in Med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The large scale of scholarly publications pose...</td>\n",
       "      <td>Muthu Kumar Chandrasekaran, Kokil Jaidka, Phil...</td>\n",
       "      <td>Thu, 8 Jun 2017 10:53:57 GMT (48kb)</td>\n",
       "      <td>Digital Libraries (cs.DL)</td>\n",
       "      <td>Joint Workshop on Bibliometric-enhanced Inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Recognizing textual entailment is a fundamenta...</td>\n",
       "      <td>Zhipeng Xie, Junfeng Hu</td>\n",
       "      <td>Thu, 25 May 2017 05:45:42 GMT (14kb)</td>\n",
       "      <td>Computation and Language (cs.CL)</td>\n",
       "      <td>Max-Cosine Matching Based Neural Models for Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It is oftentimes impossible to understand how ...</td>\n",
       "      <td>Wenbo Guo, Kaixuan Zhang, Lin Lin, Sui Huang, ...</td>\n",
       "      <td>Tue, 23 May 2017 23:51:37 GMT (731kb,D)</td>\n",
       "      <td>Learning (cs.LG)</td>\n",
       "      <td>Towards Interrogating Discriminative Machine L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, we demonstrate how the state-of...</td>\n",
       "      <td>Tao Ding, Warren K. Bickel, Shimei Pan</td>\n",
       "      <td>Tue, 16 May 2017 10:37:52 GMT (78kb,D) [v2] We...</td>\n",
       "      <td>Computation and Language (cs.CL)</td>\n",
       "      <td>Social Media-based Substance Use Prediction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           abstract  \\\n",
       "0           0  This paper advances the state of the art in te...   \n",
       "1           1  The large scale of scholarly publications pose...   \n",
       "2           2  Recognizing textual entailment is a fundamenta...   \n",
       "3           3  It is oftentimes impossible to understand how ...   \n",
       "4           4  In this paper, we demonstrate how the state-of...   \n",
       "\n",
       "                                              author  \\\n",
       "0                Hossein Hematialam, Wlodek Zadrozny   \n",
       "1  Muthu Kumar Chandrasekaran, Kokil Jaidka, Phil...   \n",
       "2                            Zhipeng Xie, Junfeng Hu   \n",
       "3  Wenbo Guo, Kaixuan Zhang, Lin Lin, Sui Huang, ...   \n",
       "4             Tao Ding, Warren K. Bickel, Shimei Pan   \n",
       "\n",
       "                                                meta  \\\n",
       "0  Tue, 13 Jun 2017 18:02:27 GMT (14kb) [v2] Wed,...   \n",
       "1                Thu, 8 Jun 2017 10:53:57 GMT (48kb)   \n",
       "2               Thu, 25 May 2017 05:45:42 GMT (14kb)   \n",
       "3            Tue, 23 May 2017 23:51:37 GMT (731kb,D)   \n",
       "4  Tue, 16 May 2017 10:37:52 GMT (78kb,D) [v2] We...   \n",
       "\n",
       "                            subject  \\\n",
       "0  Computation and Language (cs.CL)   \n",
       "1         Digital Libraries (cs.DL)   \n",
       "2  Computation and Language (cs.CL)   \n",
       "3                  Learning (cs.LG)   \n",
       "4  Computation and Language (cs.CL)   \n",
       "\n",
       "                                               title  \n",
       "0  Identifying Condition-Action Statements in Med...  \n",
       "1  Joint Workshop on Bibliometric-enhanced Inform...  \n",
       "2  Max-Cosine Matching Based Neural Models for Re...  \n",
       "3  Towards Interrogating Discriminative Machine L...  \n",
       "4        Social Media-based Substance Use Prediction  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv('./text_mining_paper.csv')\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preprocess data\n",
    "\n",
    "- abstract 컬럼에서 2글자 이상의 알파벳만 뽑아낸다.\n",
    "- Counter를 활용해서 빈도수를 구하고 2번 이상 반복되어 나온 단어만 뽑아낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstracts = list(papers['abstract'])\n",
    "corpus = list(map(lambda x : re.findall('[a-z]{2,}',x.lower()), abstracts))\n",
    "\n",
    "tokens = sum(corpus, [])\n",
    "tokens = Counter(tokens)\n",
    "tokens = [token[0] for token in tokens.items() if token[1] >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word2Vec\n",
    "\n",
    "### 2.1 Vectorize\n",
    "\n",
    "- 단어 리스트를 벡터화하고 메모리 정리\n",
    "- configuration\n",
    "    + size : feature vector의 차원\n",
    "    + alpha : initial learning rate\n",
    "    + window : 앞 뒤로 몇 단어까지 볼 것인지\n",
    "    + sg : skip-gram 방법의 사용여부. 1이면 skip-gram, 0이면 CBOW\n",
    "    + min_count : 단어의 최소 빈도. 이 이하의 단어는 무시한다.\n",
    "    + workers : 프로세서 몇 개 써서 병렬처리 할 것인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {'size' :100, 'alpha' : 0.025, 'window' : 5, 'sg' : 1, 'min_count' : 2}\n",
    "model = Word2Vec(sentences = corpus, **config)\n",
    "model.init_sims(replace = True) # 필요없는 메모리 unload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 단어 간 유사도 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: 'this', 'paper'\n",
      "similarity: 0.9951527331584714\n"
     ]
    }
   ],
   "source": [
    "word_sim = model.similarity(tokens[0], tokens[1])\n",
    "print(\"words: '{}', '{}'\".format(tokens[0], tokens[1]))\n",
    "print(\"similarity: {}\".format(word_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 유사한 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('we', 0.9972541928291321),\n",
       " ('in', 0.9955449104309082),\n",
       " ('paper', 0.9951527714729309),\n",
       " ('propose', 0.9938578009605408),\n",
       " ('study', 0.9935561418533325),\n",
       " ('method', 0.9916635751724243),\n",
       " ('approach', 0.991506040096283),\n",
       " ('also', 0.991470456123352),\n",
       " ('new', 0.9914051294326782),\n",
       " ('problem', 0.9913595914840698),\n",
       " ('present', 0.9911965131759644),\n",
       " ('an', 0.9911403656005859),\n",
       " ('the', 0.9908382892608643),\n",
       " ('novel', 0.9907150268554688),\n",
       " ('how', 0.9906813502311707),\n",
       " ('proposed', 0.9906740188598633),\n",
       " ('show', 0.9902957677841187),\n",
       " ('is', 0.9901669025421143),\n",
       " ('presents', 0.9901626110076904),\n",
       " ('technique', 0.9900466799736023)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(tokens[0], topn = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 단어 간 관계 (King-Queen)\n",
    "\n",
    "- positive: 해당 단어들과 긍정적인 관계\n",
    "- negative: 해당 단어들과 부정적 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('popular', 0.9987698793411255),\n",
       " ('sentences', 0.9987324476242065),\n",
       " ('ontologies', 0.9987238049507141),\n",
       " ('database', 0.9987122416496277),\n",
       " ('categories', 0.998700737953186),\n",
       " ('science', 0.9986943602561951),\n",
       " ('numbers', 0.9986836910247803),\n",
       " ('indices', 0.9986716508865356),\n",
       " ('mns', 0.9986706972122192),\n",
       " ('answering', 0.9986652135848999)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive = ['experimental', 'words'], negative = ['that'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Embedding된 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words length: 2281\n",
      "['the', 'of', 'and', 'to', 'in', 'is', 'for', 'we', 'text', 'this']\n"
     ]
    }
   ],
   "source": [
    "print('Words length: {}'.format(len(model.wv.index2word)))\n",
    "print(model.wv.index2word[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05594978,  0.05807013, -0.03238869, -0.07171033,  0.05283086,\n",
       "       -0.06667535,  0.06541217, -0.04155858, -0.03341519,  0.11654437,\n",
       "        0.20107394,  0.14403497, -0.06954887,  0.1761362 , -0.04633851,\n",
       "       -0.07623592, -0.05029421, -0.04052194, -0.05250368,  0.06357939,\n",
       "       -0.21229286,  0.04722983, -0.03840394,  0.03564699,  0.07652467,\n",
       "        0.01386526, -0.04466556,  0.05193227, -0.09246389,  0.05370577,\n",
       "        0.282792  , -0.1118412 , -0.17727992,  0.07671122, -0.06332225,\n",
       "       -0.01372707,  0.01543607, -0.13429877,  0.17193122,  0.16334276,\n",
       "       -0.0075834 ,  0.00768877,  0.04423469,  0.09267427,  0.10473999,\n",
       "       -0.23148984, -0.04500943,  0.04297513,  0.05064177, -0.03340086,\n",
       "        0.0583695 ,  0.10503582,  0.15592501,  0.04505303, -0.02601505,\n",
       "       -0.02186228, -0.06606573, -0.15155126,  0.07642452, -0.00750054,\n",
       "        0.17220958, -0.17409481, -0.0294145 , -0.06806629, -0.0271793 ,\n",
       "       -0.1173178 , -0.00774782,  0.07125244,  0.20547967, -0.01588257,\n",
       "       -0.09717514,  0.05808031, -0.01605292,  0.05090218, -0.06882011,\n",
       "       -0.08968716,  0.10288644, -0.05759958, -0.12384731, -0.04028495,\n",
       "       -0.06357274, -0.02507774,  0.07237262,  0.1441154 ,  0.17564104,\n",
       "       -0.00693738, -0.20014735,  0.08688552, -0.00228825,  0.11400947,\n",
       "       -0.21617143,  0.08114237,  0.02607224,  0.03669936, -0.02242013,\n",
       "       -0.10668922,  0.0883088 ,  0.01234527, -0.03383914, -0.13906224], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_word = model.wv.index2word\n",
    "embedding = [model[token] for token in my_word]\n",
    "embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape: (2281, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding = np.asarray(embedding)\n",
    "print(\"embedding shape: {}\".format(embedding.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
